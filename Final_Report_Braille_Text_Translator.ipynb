{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9b3eb35",
   "metadata": {},
   "source": [
    "# Final Project - Braille Text Translator\n",
    "## SCC0251 - Image Processing\n",
    "\n",
    "### Students\n",
    "* Caio Augusto Duarte Basso - NUSP 10801173\n",
    "* Gabriel Garcia Lorencetti - NUSP 10691891\n",
    "* Leonardo Rossi Luiz - NUSP 10851691\n",
    "* Witor Matheus Alves de Oliveira - NUSP 10692190\n",
    "\n",
    "\n",
    "### Main objective\n",
    "The main objective of this project is to build a program able to recognize letters of a braille text present in an image digitally generated, i.e, given an input image, containing a text in braille, perform the translation to the alphabetic writing system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf75e36",
   "metadata": {},
   "source": [
    "### Iput images\n",
    "The images used in this project were digitally generated, with the aid of a Braille letter dictionary and a code (which will be shown below) capable of generating Braille sentences, given an input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3406a4ff",
   "metadata": {},
   "source": [
    "### Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58970cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import imageio\n",
    "import scipy\n",
    "import scipy.ndimage\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import morphology\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fc8e4d",
   "metadata": {},
   "source": [
    "### Generating a Braille Image\n",
    "Given an input sentence, and with the help of the dictionary, the code generates an image containing the sentence in the Braille system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3e8f04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_braille_image(word):\n",
    "    letters = [Image.open(x) for x in ['dictionary/a.png', 'dictionary/b.png', 'dictionary/c.png', 'dictionary/d.png',\n",
    "                                       'dictionary/e.png', 'dictionary/f.png', 'dictionary/g.png', 'dictionary/h.png',\n",
    "                                       'dictionary/i.png', 'dictionary/j.png', 'dictionary/k.png', 'dictionary/l.png',\n",
    "                                       'dictionary/m.png', 'dictionary/n.png', 'dictionary/o.png', 'dictionary/p.png',\n",
    "                                       'dictionary/q.png', 'dictionary/r.png', 'dictionary/s.png', 'dictionary/t.png',\n",
    "                                       'dictionary/u.png', 'dictionary/v.png', 'dictionary/w.png', 'dictionary/x.png',\n",
    "                                       'dictionary/y.png', 'dictionary/z.png', 'dictionary/_space.png'\n",
    "                                      ]]\n",
    "\n",
    "    images = []\n",
    "    for letter in word:\n",
    "        if letter != ' ':\n",
    "            images.append(letters[ord(letter)-ord('a')])\n",
    "        else: images.append(letters[26])\n",
    "    widths, heights = zip(*(i.size for i in images))\n",
    "\n",
    "    total_width = sum(widths)\n",
    "    max_height = max(heights)\n",
    "\n",
    "    new_im = Image.new('RGB', (total_width, max_height))\n",
    "\n",
    "    x_offset = 0\n",
    "    for im in images:\n",
    "      new_im.paste(im, (x_offset,0))\n",
    "      x_offset += im.size[0]\n",
    "\n",
    "    word_chunks = word.split(' ')\n",
    "    img_name = word_chunks[0] +'.png'\n",
    "    new_im.save(img_name)\n",
    "\n",
    "    return img_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e042f67d",
   "metadata": {},
   "source": [
    "###  Preprocessing and quantisation\n",
    "After performing the image generation, we will transform the image to grayscale using the Luminance method. Afterwards, as the image has only two colors, black and white, we will quantize the image to use only 1 bit, which will help us to make subsequent calculations more efficient. Finally, we apply the closing function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a6782e",
   "metadata": {},
   "source": [
    "#### Function declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dc99d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def To_grayscale(img):    \n",
    "    imgA = np.floor(img[:,:,0] * 0.299 + img[:,:,1] * 0.587 + img[:,:,2] * 0.114)\n",
    "    imgA = imgA.astype('uint8')\n",
    "    return imgA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "577ecd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Quantisation (img, b):\n",
    "    img = np.right_shift(img, 8-b)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4e781a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def applying_filters(img, bits):\n",
    "    img = To_grayscale(img)\n",
    "    img = Quantisation(img, bits)\n",
    "    img = morphology.closing(img, morphology.disk(4)).astype(np.uint8)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237c12d5",
   "metadata": {},
   "source": [
    "#### Reading and applying the functions on the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d06b31b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Enter 0 if you want to use an image already available in our database (under \"images/...\")\n",
      " - Enter 1 if you want to generate the image with our braille text generator\n",
      "1\n",
      "Type a word or sentence to create braille image.\n",
      "xexeu\n"
     ]
    }
   ],
   "source": [
    "print(\" - Enter 0 if you want to use an image already available in our database (under \\\"images/...\\\")\")\n",
    "print(\" - Enter 1 if you want to generate the image with our braille text generator\")\n",
    "\n",
    "function = input()\n",
    "menu = False\n",
    "\n",
    "while(menu == False):\n",
    "    if function == '0':\n",
    "        img_name = input().rstrip() # read reference image's name\n",
    "        menu = True\n",
    "    elif function == '1':\n",
    "        print(\"Type a word or sentence to create braille image.\")\n",
    "        word = input().rstrip()\n",
    "        img_name = generate_braille_image(word)\n",
    "        menu = True\n",
    "    else:\n",
    "        print(\"Try again\")\n",
    "        function = input()\n",
    "        \n",
    "\n",
    "img_b = imageio.imread(img_name)\n",
    "img = applying_filters(img_b, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9831f868",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(2, 1)\n",
    "f.set_size_inches(13, 7)\n",
    "axarr[0].imshow(img_b, cmap=\"gray\", vmin=0, vmax=255)\n",
    "axarr[1].imshow(img, cmap=\"gray\", vmin=0, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b4ea67",
   "metadata": {},
   "source": [
    "### Applying the functions to the reference points\n",
    "\n",
    "To identify each letter, we will use two reference images: one representing the left dots of each Braille letter, and one representing the right dots. For this, we will read both and apply the same functions that we applied to the image that contains the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f341e4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### reading image #######\n",
    "dot_left_b = imageio.imread(\"dictionary/_left_dot.png\")\n",
    "dot_right_b = imageio.imread(\"dictionary/_right_dot.png\")\n",
    "#############################\n",
    "\n",
    "\n",
    "###### Preprocessing and Quantisation ######\n",
    "dot_left = applying_filters(dot_left_b, 1)\n",
    "dot_right = applying_filters(dot_right_b, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0f919e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(2, 1)\n",
    "f.set_size_inches(18, 8)\n",
    "axarr[0].imshow(dot_left, cmap=\"gray\", vmin=0, vmax=1)\n",
    "axarr[1].imshow(dot_right, cmap=\"gray\", vmin=0, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3cfe2f",
   "metadata": {},
   "source": [
    "### Dividing the image into blocks\n",
    "We know that each letter is $50px$ wide, and that the image width is $M$. So, we will split our image into $\\frac{M}{50}$ blocks (where each block will represent a letter). As each Braille letter is represented by up to 6 dots, we will divide each letter into 6 smaller blocks, each one having a place that can have a dot. So, in total, we will have $\\frac{(6M)}{50}$ windows that will be compared with the *dot_left* and *dot_right* images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e7c210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def letter_representation(img, bits):\n",
    "    \n",
    "    N,M = img.shape\n",
    "    windows = np.empty((int(M/50)*6, 18, 25))\n",
    "\n",
    "    a = 0\n",
    "    for i in range (0, M-1, 50): # creating windows\n",
    "            temp_wind = img[:,i:i+50]\n",
    "            n,m = temp_wind.shape\n",
    "            windows[a] = temp_wind[:int(n/3),:int(m/2)] # 1\n",
    "            windows[a+1] = temp_wind[:int(n/3),int(m/2):m] # 01\n",
    "            windows[a+2] = temp_wind[int(n/3):int(2*n/3),:int(m/2)] # 00/1\n",
    "            windows[a+3] = temp_wind[int(n/3):int(2*n/3),int(m/2):m] # 00/01\n",
    "            windows[a+4] = temp_wind[int(2*n/3):n,:int(m/2)] # 00/00/1\n",
    "            windows[a+5] = temp_wind[int(2*n/3):n,int(m/2):m] # 00/00/01\n",
    "            a += 6\n",
    "            \n",
    "    return windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84834ecb",
   "metadata": {},
   "source": [
    "### Euclidean distance calculation\n",
    "To compare the windows that were created earlier with the *dot_left* and *dot_right* images, we will use the Euclidean distance, which calculates the line segment between the two points, and then add all the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a707d136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Difference(a, b):\n",
    "    np.seterr(all='ignore')\n",
    "    return np.sqrt(np.sum((a-b)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f991416",
   "metadata": {},
   "source": [
    "### Finding the shortest distance\n",
    "Here, we will build a matrix of size $\\frac{M}{50}$ (number of letters in the image) by $6$. Each row will represent a letter present in our image, and each column a dot. If the position is $0$, that window does not have a dot, if the position has the value $1$, a dot has been identified. The representation of each point is carried out as follows:\n",
    "\n",
    "![title](images/letter_value.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4d5440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortestDistance(windows, left, right, M):\n",
    "    min_dist = sys.maxsize\n",
    "    close = -1\n",
    "    text = [[0]*6]\n",
    "    \n",
    "    # calculating the distances and finding the closest window\n",
    "    a = 0\n",
    "    for y in range (int(M/50)):\n",
    "        letter_value = np.zeros((1,6), dtype=np.int8)\n",
    "        for i in range(6):\n",
    "            if Difference(left, windows[a+i]) <= 0.0001 or Difference(right, windows[a+i]) <= 0.0001:\n",
    "                letter_value[0][i] = 1\n",
    "                \n",
    "        text = np.append(text, letter_value, axis=0)\n",
    "        a += 6\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f54845",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "M, N = img.shape\n",
    "\n",
    "windows = letter_representation(img, 1)\n",
    "text_value = shortestDistance(windows, dot_left, dot_right, N)\n",
    "print(\"Dot representation matrix:\")\n",
    "print(text_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6959d6f",
   "metadata": {},
   "source": [
    "### Gerando o dicionÃ¡rio\n",
    "Using the same logic as before, here we generate a 6-position vector for each letter of the alphabet, so that we can identify in the *text_value* matrix calculated above, which letter each vector represents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf06cd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando dicionario de cada letra com seu respectivo valor vetorial\n",
    "dic = {}\n",
    "alphabet = ['dictionary/a.png', 'dictionary/b.png', 'dictionary/c.png', 'dictionary/d.png', 'dictionary/e.png', \n",
    "            'dictionary/f.png', 'dictionary/g.png', 'dictionary/h.png', 'dictionary/i.png', 'dictionary/j.png', \n",
    "            'dictionary/k.png', 'dictionary/l.png', 'dictionary/m.png', 'dictionary/n.png', 'dictionary/o.png', \n",
    "            'dictionary/p.png', 'dictionary/q.png', 'dictionary/r.png', 'dictionary/s.png', 'dictionary/t.png', \n",
    "            'dictionary/u.png', 'dictionary/v.png', 'dictionary/w.png', 'dictionary/x.png', 'dictionary/y.png', \n",
    "            'dictionary/z.png'\n",
    "           ]\n",
    "\n",
    "for temp in alphabet:\n",
    "    temp_img = imageio.imread(temp)\n",
    "    temp_img = applying_filters(temp_img, 1)\n",
    "    M, N = temp_img.shape\n",
    "    temp_img = letter_representation(temp_img, 1)\n",
    "    dic[temp[11]] = list(shortestDistance(temp_img, dot_left, dot_right, M)[1])\n",
    "dic[' '] = [0,0,0,0,0,0]\n",
    "\n",
    "print(dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b800d00",
   "metadata": {},
   "source": [
    "### Final Result\n",
    "Finally, with the vector and dictionary calculated, simply relate them to generate the final text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2401cb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_text = \"\"\n",
    "for i in range(text_value.shape[0]):\n",
    "    for key, values in dic.items():\n",
    "        if(list(text_value[i]) == list(values)):\n",
    "            final_text += key\n",
    "            \n",
    "print(\"Translated text:\", final_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
